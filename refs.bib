@incollection{goodfellow2014generative,
    title = {Generative Adversarial Nets},
    author = {Goodfellow, Ian and 
        Pouget-Abadie, Jean and 
        Mirza, Mehdi and 
        Xu, Bing and 
        Warde-Farley, David and 
        Ozair, Sherjil and 
        Courville, Aaron and 
        Bengio, Yoshua},
    booktitle = {Advances in Neural Information Processing Systems 27},
    editor = {Z. Ghahramani and 
        M. Welling and C. Cortes and N. D. Lawrence and K. Q. Weinberger},
    pages = {2672--2680},
    year = {2014},
    publisher = {Curran Associates, Inc.},
    url = {http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf}
}

@ARTICLE{ganin2014unsupervised,
    title = {Unsupervised Domain Adaptation by Backpropagation},
    author = {Ganin, Yaroslav and Lempitsky, Victor},
    journal = {ArXiv e-prints},
    archivePrefix = {arXiv},
    eprint = {1409.7495},
    primaryClass = {stat.ML},
    keywords = {Statistics - Machine Learning, 
        Computer Science - Learning, 
        Computer Science - Neural and Evolutionary Computing},
    year = {2014},
    month = sep,
    adsurl = {http://adsabs.harvard.edu/abs/2014arXiv1409.7495G},
    adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{2016arXiv160502688short,
    author = {{Theano Development Team}},
    title = "{Theano: A {Python} framework for fast computation of mathematical expressions}",
    journal = {arXiv e-prints},
    volume = {abs/1605.02688},
    primaryClass = "cs.SC",
    keywords = {Computer Science - Symbolic Computation, Computer Science - Learning, Computer Science - Mathematical Software},
    year = {2016},
    month = may,
    url = {http://arxiv.org/abs/1605.02688},
}

@article{MerrienboerBDSW15,
    author    = {Bart van Merri{\"{e}}nboer and
        Dzmitry Bahdanau and
            Vincent Dumoulin and
            Dmitriy Serdyuk and
            David Warde{-}Farley and
            Jan Chorowski and
            Yoshua Bengio},
    title     = {Blocks and Fuel: Frameworks for deep learning},
    journal   = {CoRR},
    volume    = {abs/1506.00619},
    year      = {2015},
    url       = {http://arxiv.org/abs/1506.00619},
    timestamp = {Wed, 01 Jul 2015 15:10:24 +0200},
    biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/MerrienboerBDSW15},
    bibsource = {dblp computer science bibliography, http://dblp.org}
}
@article{leggetter1995maximum,
  title={Maximum likelihood linear regression for speaker adaptation of continuous density hidden Markov models},
  author={Leggetter, Christopher J and Woodland, Philip C},
  journal={Computer Speech \& Language},
  volume={9},
  number={2},
  pages={171--185},
  year={1995},
  publisher={Elsevier}
}

@article{hinton2012deep,
  title={Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups},
  author={Hinton, Geoffrey and Deng, Li and Yu, Dong and Dahl, George E and Mohamed, Abdel-rahman and Jaitly, Navdeep and Senior, Andrew and Vanhoucke, Vincent and Nguyen, Patrick and Sainath, Tara N and others},
  journal={IEEE Signal Processing Magazine},
  volume={29},
  number={6},
  pages={82--97},
  year={2012},
  publisher={IEEE}
}

@article{parihar2002aurora,
    title={Aurora working group: DSR front end LVCSR evaluation AU/385/02},
    author={Parihar, N and Picone, J},
    journal={Inst. for Signal and Information Process, Mississippi State University, Tech. Rep},
    volume={40},
    pages={94},
    year={2002}
}

@article{yusuke2016adversarial,
    title={Adversarial Multi-task Learning of Deep Neural Networks for Robust Speech Recognition},
    author={Shunohara, Yusuke},
    year={2016},
    journal={Interspeech 2016},
    pages={2369--2372},
}

@inproceedings{seltzer2013investigation,
    author = {Seltzer, Mike and Yu, Dong and Wang, Yongqiang},
    title = {An Investigation of Deep Neural Networks for Noise Robust Speech Recognition},
    booktitle = {ICASSP 2013},
    year = {2013},
    month = {January},
    abstract = {
    Recently, a new acoustic model based on deep neural networks (DNN) has been introduced. While the DNN has generated significant improvements over GMM based systems on several tasks, there has been no evaluation of the robustness of such systems to environmental distortion. In this paper, we investigate the noise robustness of DNN based acoustic models and find that they can match state-of-the-art performance on the Aurora 4 task without any explicit noise compensation. This performance can be further improved by incorporating information about the environment into DNN training using a new method called noise-aware training. When combined with the recently proposed dropout training technique, a 7.5% relative improvement over the previously best published result on this task is achieved using only a single decoding pass and no additional decoding complexity compared to a standard DNN.
    },
    publisher = {IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)},
    url = {https://www.microsoft.com/en-us/research/publication/an-investigation-of-deep-neural-networks-for-noise-robust-speech-recognition/},
    address = {},
    pages = {},
    journal = {},
    volume = {},
    chapter = {},
    isbn = {},
}
